{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NzyqehHjUlG"
   },
   "source": [
    "# ML in Cybersecurity: Project I\n",
    "\n",
    "## Team\n",
    "  * **Team name**: *GoodFellows*\n",
    "  * **Members**:  *fill this in. format:  Md Abdul Kadir (s8mdkadi@stud.uni-saarland.de), Hasan Md Tusfiqur Alam (s8haalam@stud.uni-saarland.de), Chirage Bhuvaneshwara (s8chbhuv@stud.uni-saarland.de) (Has already completed the assignments in MLCySec WS18/19 and is required to submit only Project 2)\n",
    "\n",
    "\n",
    "## Logistics\n",
    "  * **Due date**: 13th November 2018, 23:59:59 (email the completed notebook to mlcysec_ws1920_staff@lists.cispa.saarland)\n",
    "  * Complete this in **teams of 3**\n",
    "  * Feel free to use the course [mailing list](https://lists.cispa.saarland/listinfo/mlcysec_ws1920_stud) to find group members.\n",
    "  \n",
    "## Timeline\n",
    "  * 31-Oct-2018: Project 1 hand-out\n",
    "  * **13-Nov-2018** (23:59:59): Email completed notebook to respective TAs\n",
    "  * 21-Nov-2018: Project 1 discussion and summary\n",
    "  \n",
    "  \n",
    "## About this Project\n",
    "In this project, you'll implement a digit classifier, based on the popular [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. The dataset is based on a seminal [paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), which immensely popularized (convolutional) neural networks. This is a great starting point for ML research and this dataset/model has been a stepping stone numerous other tasks such as [GANs](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), [Adversarial Perturbations](https://arxiv.org/abs/1412.6572) and so many more!\n",
    "\n",
    "This dataset consists of data $\\mathcal{D} = \\{x_i, y_i\\}_{i=1}^N$, where $x_i$ is a 28x28 pixel grayscale image and $y_i$ is a scalar represeting digits between 0-9. The notebook will guide you to load this data, implement classifiers $\\hat{y_i} = f_w(x_i)$  and analyze results. By doing so, you'll have a ML model that works on real data!\n",
    "\n",
    "To put things into context, have a look at Slide 21 in the [second](https://cms.cispa.saarland/mlcysec19/dl/4/2019-10-24-ml.pdf) lecture. Within this framework, the following blocks of this project are fixed:\n",
    "  * *Real-world problem*: Digit classification\n",
    "  * *Performance metric*: Mean accuracy i.e., $ \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}[\\hat{y_i} = y_i]$, where $\\mathbb{1}[\\hat{y_i} = y_i]$ is 1 if your model predicted the right digit for the $i$-th digit and 0 otherwise.\n",
    "  * *Data*: The MNIST dataset\n",
    "\n",
    "You'll make the the following design-choices:\n",
    " * *Choice of Model*: A model family (Non-parametric methods, Linear classifiers, Neural Networks, etc.)\n",
    " * *ML Model*: Specific model (e.g., SVM with a polynomial kernel)\n",
    " * *Loss/Risk*\n",
    " * *Optimization*\n",
    "\n",
    "\n",
    "## A Note on Grading\n",
    "The grading for this project will depend on:\n",
    " 1. Functional digit classifier\n",
    "   * Following a well-defined ML pipeline\n",
    "   * Developing 3 classification models (keep them diverse and ideally of increasing complexity)\n",
    "   * Obtaining reasonable accuracies (>80%) on a held-out test set\n",
    " 1. Analysis\n",
    "   * Which methods work better than the rest and why?\n",
    "   * Which hyper-parameters and design-choices were important in each of your methods?\n",
    "   * Quantifying influence of these hyper-parameters on loss and/or validation accuracies\n",
    "   * Trade-offs between methods, hyper-parameters, design-choices\n",
    "    * Anything else you find interesting (this part is open-ended)\n",
    "  \n",
    " A note on (1.): \n",
    "  * Choose your models that aids good insights. We require at least one non-Neural Network (e.g., SVM, KNN) and one Neural Network model (e.g., MLP, CNN).\n",
    "  * We definitely don't expect all three models to achieve >99% test accuracies!\n",
    "\n",
    "## Grading Details\n",
    " * 5 points for loading and visualization \n",
    " * 25x3 points for models. Per model:\n",
    "   * 4 points for written description \n",
    "   * 7 points for implementation\n",
    "   * 7 points for evaluation\n",
    "   * 7 points for summary\n",
    " * 15 points for final summary (Section 3)\n",
    " * 5 points for clean code\n",
    " \n",
    "## Filling-in the Notebook\n",
    "You'll be submitting this very notebook that is filled-in with your code and analysis. Make sure you submit one that has been previously executed in-order. (So that results/graphs are already visible upon opening it). \n",
    "\n",
    "The notebook you submit **should compile** (or should be self-contained and sufficiently commented). Check tutorial 1 on how to set up the Python3 environment.\n",
    "\n",
    "\n",
    "**The notebook is your project report. So, to make the report readable, omit code for techniques/models/things that did not work. You can use final summary to provide report about these codes.**\n",
    "\n",
    "It is extremely important that you **do not** re-order the existing sections. Apart from that, the code blocks that you need to fill-in are given by:\n",
    "```\n",
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#\n",
    "```\n",
    "Feel free to break this into multiple-cells. It's even better if you interleave explanations and code-blocks so that the entire notebook forms a readable \"story\".\n",
    "\n",
    "\n",
    "## Code of Honor\n",
    "We encourage discussing ideas and concepts with other students to help you learn and better understand the course content. However, the work you submit and present **must be original** and demonstrate your effort in solving the presented problems. **We will not tolerate** blatantly using existing solutions (such as from the internet), improper collaboration (e.g., sharing code or experimental data between groups) and plagiarism. If the honor code is not met, no points will be awarded.\n",
    "\n",
    " \n",
    " ## Versions\n",
    "  * v2.0: Added pytorch\n",
    "  * v1.1: Added Code of Honor\n",
    "  * v1.0: Initial notebook\n",
    "  \n",
    "  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ewNwfFvbFaR"
   },
   "outputs": [],
   "source": [
    "import time \n",
    " \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import json \n",
    "import time \n",
    "import pickle \n",
    "import sys \n",
    "import csv \n",
    "import os \n",
    "import os.path as osp \n",
    "import shutil \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    " \n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots \n",
    "plt.rcParams['image.interpolation'] = 'nearest' \n",
    "plt.rcParams['image.cmap'] = 'gray' \n",
    " \n",
    "# for auto-reloading external modules \n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "640GrzbOevr0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x119961d5970>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load other libraries here.\n",
    "# Keep it minimal! We should be easily able to reproduce your code.\n",
    "import torch\n",
    "import sklearn\n",
    "import torchvision\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# We only support sklearn and pytorch.\n",
    "\n",
    "# Please set random seed to have reproduceable results, e.g. torch.manual_seed(123)\n",
    "torch.manual_seed(73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxi-lLD0mKHD"
   },
   "source": [
    "Helpers\n",
    "\n",
    "In case you choose to have some methods you plan to reuse during the notebook, define them here. This will avoid clutter and keep rest of the notebook succinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBbigqdEmKd8"
   },
   "outputs": [],
   "source": [
    "def identity_func(foo):\n",
    "    return foo\n",
    "\n",
    "def PIL_to_np(image):\n",
    "    return np.array(image)\n",
    "\n",
    "# You can use this function to flatten 2D inputs\n",
    "def flatten_input_pixels(x_input):\n",
    "    result = []\n",
    "    for i in range(len(x_input)):\n",
    "        result.append(x_input[i].flatten())\n",
    "    return np.array(result, np.uint8)  # [n_samples, n_features]\n",
    "\n",
    "\n",
    "# You can use this function to plot the accuracy of the models with different parametes\n",
    "def plot_scores(x, y, title = \"Title\", x_label = \"X\", y_label = \"Y\"):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1)\n",
    "\n",
    "    ax.plot(x, y)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_ylim(0.6, 1.0)\n",
    "\n",
    "# You can use this function to visualize input images and the predictions of your models\n",
    "# \"y_pred\" is output of your model \n",
    "# \"n_val\" is number of instances in test or validation sets\n",
    "def vis_predictions(x_eval, y_pred, n_val):\n",
    "    rows, cols = 4, 3\n",
    "\n",
    "    fig,ax = plt.subplots(nrows = rows, ncols = cols)\n",
    "\n",
    "    ids = np.random.randint(0,n_val,rows*cols)\n",
    "    for i in range(cols):   \n",
    "        for j in range(rows):\n",
    "            ax[j][i].set_title('predicted label: {0}'. format(y_pred[ids[(i*rows)+j]]))\n",
    "            two_d = (np.reshape(x_eval[ids[(i*rows)+j]], (28, 28))).astype(np.uint8)\n",
    "            ax[j][i].imshow(two_d)\n",
    "            ax[j][i].axes.get_xaxis().set_visible(False)\n",
    "            ax[j][i].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "    plt.tight_layout()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1pcmKkyjT7y"
   },
   "source": [
    "# 1. Loading and Visualizing data (5 points)\n",
    "\n",
    "In this section, you'll need to prepare the MNIST data for the experiments you'll be conducting for the remainder of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIU9Q762fmoT"
   },
   "source": [
    "## 1.1. Load Data\n",
    "\n",
    "Here you'll load the MNIST data into memory. The end-goal is to two have the following variables:\n",
    "  * `x_trainval`, `x_test`: of shape $N \\times d_1 \\times d_2 \\dots$ (e.g., $N \\times 784$. 784 since you could flatten each 28x28 pixel image into a single vector)\n",
    "  * `y_trainval`, `y_test`: of shape $N \\times K$ (K = 1 or 10 depending on how you plan to represent the ground-truth digit annotation)\n",
    "\n",
    "You can either do this by:\n",
    "  1. Downloading the MNIST dataset, unpacking and preparing it yourself to have fine-grained control\n",
    "  1. Using high-level existing functions, such as the one provided by  [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist).\n",
    "  \n",
    "  \n",
    "  In either case, it is important that you have disjoint trainval and test splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kYacpo_jvao"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_trainval.shape = (60000, 784),  y_trainval.shape = (60000,)\n",
      "x_test.shape = (10000, 784),  y_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "# loading dataset\n",
    "dataset_dir = 'data/mnist'\n",
    "training_data = torchvision.datasets.MNIST(dataset_dir,train=True, transform=PIL_to_np, \n",
    "                                     target_transform=None, download=True)\n",
    "test_data = torchvision.datasets.MNIST(dataset_dir,train=False, transform=PIL_to_np, \n",
    "                                     target_transform=None, download=True)\n",
    "\n",
    "# Loadin training data in to numpy array\n",
    "\n",
    "x_trainval_3d = np.array([training_data[i][0] for i in range(len(training_data))])\n",
    "x_trainval = flatten_input_pixels(x_trainval_3d)\n",
    "y_trainval = np.array([training_data[i][1] for i in range(len(training_data))])\n",
    "\n",
    "# Loading test data into numpy array\n",
    "\n",
    "x_test_3d = np.array([test_data[i][0] for i in range(len(test_data))])\n",
    "x_test =  flatten_input_pixels(x_test_3d)\n",
    "y_test = np.array([test_data[i][1] for i in range(len(test_data))])\n",
    "\n",
    "\n",
    "print('x_trainval.shape = {},  y_trainval.shape = {}'.format(x_trainval.shape, y_trainval.shape))\n",
    "print('x_test.shape = {},  y_test.shape = {}'.format(x_test.shape, y_test.shape))\n",
    "\n",
    "#\n",
    "# Feel free to have multiple variables in case your models are designed for different formats\n",
    "# For instance, in case your model requires Nx28x28 inputs, declare x_trainval_3d, etc.\n",
    "\n",
    "# Tip: Set this to a tiny number (such 0.05) to aid debugging\n",
    "# After all, you do not want to train/evaluate on the entire dataset to find bugs\n",
    "DEBUG_FRAC = 0.05\n",
    "x_trainval = x_trainval[:int(len(x_trainval)*DEBUG_FRAC)]\n",
    "y_trainval = y_trainval[:int(len(y_trainval)*DEBUG_FRAC)]\n",
    "# Use the debuging idea for 3d input\n",
    "x_trainval_3d = x_trainval_3d[:int(len(x_trainval_3d)*DEBUG_FRAC)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eA6_cejNjzYw"
   },
   "source": [
    "#### 1.2. Visualize Data\n",
    "\n",
    "To get the hang of your data you'll be training a digit classifier on, visualize it.\n",
    "\n",
    "Examples of ways to visualize it:\n",
    "  * Given a digit, display few randomly sampled images for this digit (the bare minimum)\n",
    "  * Visualize as a grid (e.g., Slide 4, [Lecture 2](https://cms.cispa.saarland/mlcysec19/dl/4/2019-10-24-ml.pdf)) using a combination of `plt.imshow` and `plt.subplots`\n",
    "  \n",
    "It's up to you to decide how you want to do this. The end-goal is for you to potentially give a trailer of the dataset to someone who hasn't seen it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dISIbt4plyoD"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize 10 examples of 10 classes. You can extend the following code:\n",
    "rows, cols = 10, 10\n",
    "fig,ax = plt.subplots(nrows = rows, ncols = cols)\n",
    "for i in range(10):\n",
    "    img_index =list(np.where(y_trainval == i))\n",
    "    rand_ten_images = random.choices(img_index[0], k=10)\n",
    "    j = 0\n",
    "    for idx in rand_ten_images:\n",
    "        img = np.reshape(x_trainval[idx], (28, 28))\n",
    "        ax[i, j].imshow(img)\n",
    "        j += 1\n",
    "\n",
    "plt.savefig('fig1.pdf')   # Save the figures\n",
    "plt.show()   # These should be some visualization of data at the end of this section\n",
    "\n",
    "# You can see an output example in the follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8sAT53jmJ8_"
   },
   "source": [
    "# 2. Digit classifiers\n",
    "\n",
    "In this section, you'll begin developing models to perform digit classification.\n",
    "\n",
    "Each model needs to be structured like so:\n",
    "  1. Give a brief reason which model you are going to train and why you choose it\n",
    "  1. Define hyper-parameters for model and optimization procedure\n",
    "  1. Define your model\n",
    "  1. Define optimization method and fit model to data\n",
    "  1. Summarize your findings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkF-7eFnpWoe"
   },
   "source": [
    "## 2.1: Model [M1]: *fill-this-in* (25 points)\n",
    "\n",
    "**Short description **: *fill this in*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVyT9Oddp3GB"
   },
   "source": [
    "### 2.1.1: Hyper-parameters\n",
    "\n",
    "Define hyper-parameters for your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yuHt4T7Vp5NC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 784)\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.05, 0.1, 0.5, 1]\n",
    "gamma_values = [0.005, 0.01, 0.05, 0.1]\n",
    "kernel_values = [\"poly\", \"rbf\"] \n",
    "parameter_space = {\"C\":c_values, \"gamma\":gamma_values, \"kernel\":kernel_values}\n",
    "\n",
    "print(x_trainval.shape)\n",
    "\n",
    "degree = np.asarray([1,2,3]) # example\n",
    "\n",
    "\n",
    "test_set = 'val'  #  or 'test'\n",
    "# Decide all your hyperparameters based on validation performance\n",
    "# Then, switch to 'test' for final evaluation\n",
    "\n",
    "if test_set == 'val':\n",
    "    train_idxs, val_idxs = ..., ...   # Fill in\n",
    "    x_train, y_train = x_trainval[train_idxs], y_trainval[train_idxs]\n",
    "    x_eval, y_eval = x_trainval[val_idxs], y_trainval[val_idxs]\n",
    "else:\n",
    "    x_train, y_train = x_trainval, y_trainval\n",
    "    x_eval, y_eval = x_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2: Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 247) (10000, 247)\n"
     ]
    }
   ],
   "source": [
    "# e.g. normalize, flatten input data.\n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(x_trainval.reshape(x_trainval.shape[0],-1))\n",
    "x_trainval_scaled = scaler.transform(x_trainval.reshape(x_trainval.shape[0],-1))\n",
    "x_test_scaled = scaler.transform(x_test.reshape(x_test.shape[0],-1))\n",
    "\n",
    "pca = PCA(0.95)\n",
    "pca.fit(x_trainval_scaled)\n",
    "\n",
    "x_trainval_reduced = pca.transform(x_trainval_scaled)\n",
    "x_test_reduced = pca.transform(x_test_scaled)\n",
    "\n",
    "print(x_trainval_reduced.shape, x_test_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkuCgPatp59X"
   },
   "source": [
    "### 2.1.3: Model\n",
    "\n",
    "Define your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qV3SuPAp6XF"
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "grid_search = sklearn.model_selection.GridSearchCV(svc, parameter_space, verbose=2, cv=2, refit=True,\n",
    "                                                  return_train_score=True, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxE6d6OXp6sU"
   },
   "source": [
    "### 2.1.4: Fit Model\n",
    "\n",
    "Define optimization procedure and fit your model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08tLwuchp68-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.05, gamma=0.005, kernel=poly ................................\n",
      "[CV] ................. C=0.05, gamma=0.005, kernel=poly, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.05, gamma=0.005, kernel=poly ................................\n",
      "[CV] ................. C=0.05, gamma=0.005, kernel=poly, total=   1.5s\n",
      "[CV] C=0.05, gamma=0.005, kernel=rbf .................................\n",
      "[CV] .................. C=0.05, gamma=0.005, kernel=rbf, total=   2.0s\n",
      "[CV] C=0.05, gamma=0.005, kernel=rbf .................................\n",
      "[CV] .................. C=0.05, gamma=0.005, kernel=rbf, total=   2.0s\n",
      "[CV] C=0.05, gamma=0.01, kernel=poly .................................\n",
      "[CV] .................. C=0.05, gamma=0.01, kernel=poly, total=   1.2s\n",
      "[CV] C=0.05, gamma=0.01, kernel=poly .................................\n",
      "[CV] .................. C=0.05, gamma=0.01, kernel=poly, total=   1.3s\n",
      "[CV] C=0.05, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=0.05, gamma=0.01, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.05, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=0.05, gamma=0.01, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.05, gamma=0.05, kernel=poly .................................\n",
      "[CV] .................. C=0.05, gamma=0.05, kernel=poly, total=   1.3s\n",
      "[CV] C=0.05, gamma=0.05, kernel=poly .................................\n",
      "[CV] .................. C=0.05, gamma=0.05, kernel=poly, total=   1.4s\n",
      "[CV] C=0.05, gamma=0.05, kernel=rbf ..................................\n",
      "[CV] ................... C=0.05, gamma=0.05, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.05, gamma=0.05, kernel=rbf ..................................\n",
      "[CV] ................... C=0.05, gamma=0.05, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.05, gamma=0.1, kernel=poly ..................................\n",
      "[CV] ................... C=0.05, gamma=0.1, kernel=poly, total=   1.3s\n",
      "[CV] C=0.05, gamma=0.1, kernel=poly ..................................\n",
      "[CV] ................... C=0.05, gamma=0.1, kernel=poly, total=   1.4s\n",
      "[CV] C=0.05, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=0.05, gamma=0.1, kernel=rbf, total=   2.3s\n",
      "[CV] C=0.05, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=0.05, gamma=0.1, kernel=rbf, total=   2.2s\n",
      "[CV] C=0.1, gamma=0.005, kernel=poly .................................\n",
      "[CV] .................. C=0.1, gamma=0.005, kernel=poly, total=   1.3s\n",
      "[CV] C=0.1, gamma=0.005, kernel=poly .................................\n",
      "[CV] .................. C=0.1, gamma=0.005, kernel=poly, total=   1.3s\n",
      "[CV] C=0.1, gamma=0.005, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.005, kernel=rbf, total=   2.0s\n",
      "[CV] C=0.1, gamma=0.005, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.005, kernel=rbf, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=0.1, gamma=0.01, kernel=poly, total=   1.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=0.1, gamma=0.01, kernel=poly, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=   2.0s\n",
      "[CV] C=0.1, gamma=0.05, kernel=poly ..................................\n",
      "[CV] ................... C=0.1, gamma=0.05, kernel=poly, total=   1.3s\n",
      "[CV] C=0.1, gamma=0.05, kernel=poly ..................................\n",
      "[CV] ................... C=0.1, gamma=0.05, kernel=poly, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.05, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.05, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.1, gamma=0.05, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.05, kernel=rbf, total=   2.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] .................... C=0.1, gamma=0.1, kernel=poly, total=   1.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] .................... C=0.1, gamma=0.1, kernel=poly, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=   2.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=   2.2s\n",
      "[CV] C=0.5, gamma=0.005, kernel=poly .................................\n",
      "[CV] .................. C=0.5, gamma=0.005, kernel=poly, total=   1.2s\n",
      "[CV] C=0.5, gamma=0.005, kernel=poly .................................\n",
      "[CV] .................. C=0.5, gamma=0.005, kernel=poly, total=   1.4s\n",
      "[CV] C=0.5, gamma=0.005, kernel=rbf ..................................\n",
      "[CV] ................... C=0.5, gamma=0.005, kernel=rbf, total=   1.6s\n",
      "[CV] C=0.5, gamma=0.005, kernel=rbf ..................................\n",
      "[CV] ................... C=0.5, gamma=0.005, kernel=rbf, total=   1.7s\n",
      "[CV] C=0.5, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=0.5, gamma=0.01, kernel=poly, total=   1.4s\n",
      "[CV] C=0.5, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=0.5, gamma=0.01, kernel=poly, total=   1.5s\n",
      "[CV] C=0.5, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.5, gamma=0.01, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.5, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.5, gamma=0.01, kernel=rbf, total=   2.0s\n",
      "[CV] C=0.5, gamma=0.05, kernel=poly ..................................\n",
      "[CV] ................... C=0.5, gamma=0.05, kernel=poly, total=   1.3s\n",
      "[CV] C=0.5, gamma=0.05, kernel=poly ..................................\n",
      "[CV] ................... C=0.5, gamma=0.05, kernel=poly, total=   1.4s\n",
      "[CV] C=0.5, gamma=0.05, kernel=rbf ...................................\n",
      "[CV] .................... C=0.5, gamma=0.05, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.5, gamma=0.05, kernel=rbf ...................................\n",
      "[CV] .................... C=0.5, gamma=0.05, kernel=rbf, total=   2.2s\n",
      "[CV] C=0.5, gamma=0.1, kernel=poly ...................................\n",
      "[CV] .................... C=0.5, gamma=0.1, kernel=poly, total=   1.3s\n",
      "[CV] C=0.5, gamma=0.1, kernel=poly ...................................\n",
      "[CV] .................... C=0.5, gamma=0.1, kernel=poly, total=   1.4s\n",
      "[CV] C=0.5, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.5, gamma=0.1, kernel=rbf, total=   2.1s\n",
      "[CV] C=0.5, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.5, gamma=0.1, kernel=rbf, total=   2.1s\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=0.005, kernel=poly, total=   1.3s\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=0.005, kernel=poly, total=   1.4s\n",
      "[CV] C=1, gamma=0.005, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.005, kernel=rbf, total=   1.7s\n",
      "[CV] C=1, gamma=0.005, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.005, kernel=rbf, total=   1.7s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total=   1.2s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total=   1.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   2.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   2.0s\n",
      "[CV] C=1, gamma=0.05, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.05, kernel=poly, total=   1.2s\n",
      "[CV] C=1, gamma=0.05, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.05, kernel=poly, total=   1.3s\n",
      "[CV] C=1, gamma=0.05, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.05, kernel=rbf, total=   2.1s\n",
      "[CV] C=1, gamma=0.05, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.05, kernel=rbf, total=   2.1s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total=   1.2s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total=   1.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   2.1s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.05, 'gamma': 0.05, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "svm_model = grid_search.fit(x_trainval_reduced, y_trainval)\n",
    "print(svm_model.best_params_)\n",
    "model_params = svm_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.05, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=model_params['C'], gamma=model_params['gamma'], kernel=model_params['kernel'])\n",
    "svc.fit(x_trainval_reduced, y_trainval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaJv_d_Dp7OM"
   },
   "source": [
    "### 2.1.5: Evaluation\n",
    "\n",
    "Evaluate your model.\n",
    "  * Evaluate models with different parameters \n",
    "  * Plot the score (accuracy) for each model using \"plot_scores\" function\n",
    "  * Report score for the best model\n",
    "  * Use \"vis_predictions\" function to visualize few examples of test/validation set with the corresponding predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZtLgPZrp7h5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9273\n",
      "[[ 949    0    2    3    3    5    9    1    8    0]\n",
      " [   0 1121    4    1    1    1    3    0    4    0]\n",
      " [   8    2  923   16   19    1    5   11   45    2]\n",
      " [   0    3    8  911    2   22    0   11   42   11]\n",
      " [   0    3    6    0  936    0    3    1    5   28]\n",
      " [   4    2    2   11   14  817    6    2   21   13]\n",
      " [  11    3   10    1   30   17  879    0    7    0]\n",
      " [   0   11   10    4   30    1    0  919   10   43]\n",
      " [   4    0    5   12   17   15    1    4  902   14]\n",
      " [   4    4    3   10   44    4    0   11   13  916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.89      0.92      1032\n",
      "           3       0.94      0.90      0.92      1010\n",
      "           4       0.85      0.95      0.90       982\n",
      "           5       0.93      0.92      0.92       892\n",
      "           6       0.97      0.92      0.94       958\n",
      "           7       0.96      0.89      0.92      1028\n",
      "           8       0.85      0.93      0.89       974\n",
      "           9       0.89      0.91      0.90      1009\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: y_pred = model.predict(x)\n",
    "y_predict = svc.predict(x_test_reduced)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_predict)\n",
    "print(accuracy)\n",
    "confusion_mat = sklearn.metrics.confusion_matrix(y_test, y_predict)\n",
    "print(confusion_mat)\n",
    "classfication_report = sklearn.metrics.classification_report(y_test, y_predict)\n",
    "print(classfication_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.9230653 , 1.33792377, 0.91056359, 1.42171645, 0.96897459,\n",
       "        1.43372166, 0.93202758, 1.5418694 , 0.85125577, 1.28606176,\n",
       "        0.97745252, 1.3997581 , 0.93998587, 1.55284739, 0.99636889,\n",
       "        1.5014863 , 0.92802083, 1.09258032, 1.03576314, 1.3967731 ,\n",
       "        0.94248021, 1.47106552, 0.94500422, 1.46011686, 0.94101453,\n",
       "        1.17436099, 0.92506027, 1.37982488, 0.92504621, 1.44517004,\n",
       "        0.92505848, 1.45414186]),\n",
       " 'std_fit_time': array([0.03038561, 0.01446319, 0.04088986, 0.02944207, 0.0084784 ,\n",
       "        0.01345479, 0.03837752, 0.01295614, 0.02440155, 0.01146889,\n",
       "        0.07280517, 0.00947356, 0.03939402, 0.07579708, 0.09670758,\n",
       "        0.00947285, 0.05036461, 0.0493691 , 0.08829343, 0.05735469,\n",
       "        0.02892292, 0.01396298, 0.04434919, 0.00297284, 0.03437543,\n",
       "        0.00448728, 0.03836203, 0.00646567, 0.03841448, 0.01100361,\n",
       "        0.04042518, 0.00701046]),\n",
       " 'mean_score_time': array([0.59092939, 0.77496982, 0.47425461, 0.76992249, 0.46920252,\n",
       "        0.76943278, 0.53159034, 0.79038703, 0.54251695, 0.76847541,\n",
       "        0.47770643, 0.7515198 , 0.46974564, 0.76545453, 0.50162601,\n",
       "        0.79437602, 0.48073483, 0.65028095, 0.50661576, 0.76594722,\n",
       "        0.48226416, 0.77843976, 0.47621453, 0.7824105 , 0.47070992,\n",
       "        0.63083315, 0.4712317 , 0.70013309, 0.4687475 , 0.76142883,\n",
       "        0.47074032, 0.76891196]),\n",
       " 'std_score_time': array([2.44711637e-02, 2.49361992e-02, 1.24440193e-02, 5.96427917e-03,\n",
       "        1.44834518e-02, 2.50148773e-03, 1.69993639e-02, 1.74525976e-02,\n",
       "        1.49276257e-02, 3.23857069e-02, 1.39737129e-02, 1.52218342e-03,\n",
       "        1.49612427e-02, 1.49464607e-03, 3.89328003e-02, 1.74521208e-02,\n",
       "        1.19905472e-02, 1.97267532e-03, 2.09830999e-02, 3.97932529e-03,\n",
       "        2.48301029e-03, 1.51753426e-03, 1.55111551e-02, 1.04311705e-02,\n",
       "        1.49925947e-02, 3.46875191e-03, 1.34723186e-02, 1.03640556e-03,\n",
       "        1.49208307e-02, 4.65869904e-04, 1.58905983e-02, 2.94446945e-05]),\n",
       " 'param_C': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.005, 0.005, 0.01, 0.01, 0.05, 0.05, 0.1, 0.1, 0.005,\n",
       "                    0.005, 0.01, 0.01, 0.05, 0.05, 0.1, 0.1, 0.005, 0.005,\n",
       "                    0.01, 0.01, 0.05, 0.05, 0.1, 0.1, 0.005, 0.005, 0.01,\n",
       "                    0.01, 0.05, 0.05, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['poly', 'rbf', 'poly', 'rbf', 'poly', 'rbf', 'poly',\n",
       "                    'rbf', 'poly', 'rbf', 'poly', 'rbf', 'poly', 'rbf',\n",
       "                    'poly', 'rbf', 'poly', 'rbf', 'poly', 'rbf', 'poly',\n",
       "                    'rbf', 'poly', 'rbf', 'poly', 'rbf', 'poly', 'rbf',\n",
       "                    'poly', 'rbf', 'poly', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.05, 'gamma': 0.005, 'kernel': 'poly'},\n",
       "  {'C': 0.05, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "  {'C': 0.05, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 0.05, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.05, 'gamma': 0.05, 'kernel': 'poly'},\n",
       "  {'C': 0.05, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  {'C': 0.05, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 0.05, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.005, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.05, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 0.005, 'kernel': 'poly'},\n",
       "  {'C': 0.5, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 0.5, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 0.05, 'kernel': 'poly'},\n",
       "  {'C': 0.5, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 0.5, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.005, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.05, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.74401596, 0.30851064, 0.85704787, 0.19680851, 0.87234043,\n",
       "        0.11303191, 0.87234043, 0.11303191, 0.8025266 , 0.50531915,\n",
       "        0.86835106, 0.21343085, 0.87234043, 0.11303191, 0.87234043,\n",
       "        0.11303191, 0.86170213, 0.75664894, 0.87234043, 0.53390957,\n",
       "        0.87234043, 0.16888298, 0.87234043, 0.11303191, 0.87034574,\n",
       "        0.79920213, 0.87234043, 0.67952128, 0.87234043, 0.21343085,\n",
       "        0.87234043, 0.16755319]),\n",
       " 'split1_test_score': array([0.79278075, 0.28141711, 0.89973262, 0.2118984 , 0.91042781,\n",
       "        0.11296791, 0.91042781, 0.11296791, 0.84625668, 0.52941176,\n",
       "        0.90842246, 0.21457219, 0.91042781, 0.11296791, 0.91042781,\n",
       "        0.11296791, 0.90374332, 0.77673797, 0.91042781, 0.55481283,\n",
       "        0.91042781, 0.17513369, 0.91042781, 0.11296791, 0.91042781,\n",
       "        0.84157754, 0.91042781, 0.70588235, 0.91042781, 0.21256684,\n",
       "        0.91042781, 0.17647059]),\n",
       " 'mean_test_score': array([0.76833333, 0.295     , 0.87833333, 0.20433333, 0.89133333,\n",
       "        0.113     , 0.89133333, 0.113     , 0.82433333, 0.51733333,\n",
       "        0.88833333, 0.214     , 0.89133333, 0.113     , 0.89133333,\n",
       "        0.113     , 0.88266667, 0.76666667, 0.89133333, 0.54433333,\n",
       "        0.89133333, 0.172     , 0.89133333, 0.113     , 0.89033333,\n",
       "        0.82033333, 0.89133333, 0.69266667, 0.89133333, 0.213     ,\n",
       "        0.89133333, 0.172     ]),\n",
       " 'std_test_score': array([2.43823089e-02, 1.35467148e-02, 2.13422981e-02, 7.54491572e-03,\n",
       "        1.90436233e-02, 3.20001138e-05, 1.90436233e-02, 3.20001138e-05,\n",
       "        2.18649666e-02, 1.20462651e-02, 2.00356268e-02, 5.70668696e-04,\n",
       "        1.90436233e-02, 3.20001138e-05, 1.90436233e-02, 3.20001138e-05,\n",
       "        2.10205192e-02, 1.00444802e-02, 1.90436233e-02, 1.04515927e-02,\n",
       "        1.90436233e-02, 3.12534445e-03, 1.90436233e-02, 3.20001138e-05,\n",
       "        2.00409601e-02, 2.11876309e-02, 1.90436233e-02, 1.31804913e-02,\n",
       "        1.90436233e-02, 4.32001536e-04, 1.90436233e-02, 4.45868252e-03]),\n",
       " 'rank_test_score': array([17, 22, 14, 25,  1, 28,  1, 28, 15, 21, 12, 23,  1, 28,  1, 28, 13,\n",
       "        18,  1, 20,  1, 26,  1, 28, 11, 16,  1, 19,  1, 24,  1, 26]),\n",
       " 'split0_train_score': array([0.91243316, 0.35294118, 0.99799465, 0.20855615, 1.        ,\n",
       "        0.11296791, 1.        , 0.11296791, 0.96457219, 0.60962567,\n",
       "        0.99933155, 0.23729947, 1.        , 0.11296791, 1.        ,\n",
       "        0.11296791, 0.9986631 , 0.94719251, 1.        , 0.94451872,\n",
       "        1.        , 0.33088235, 1.        , 0.22259358, 1.        ,\n",
       "        0.9986631 , 1.        , 0.99933155, 1.        , 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " 'split1_train_score': array([0.90558511, 0.29654255, 0.99534574, 0.20478723, 1.        ,\n",
       "        0.11303191, 1.        , 0.11303191, 0.96210106, 0.60837766,\n",
       "        1.        , 0.22406915, 1.        , 0.11303191, 1.        ,\n",
       "        0.11303191, 0.99601064, 0.92952128, 1.        , 0.95146277,\n",
       "        1.        , 0.24335106, 1.        , 0.22273936, 1.        ,\n",
       "        0.99800532, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " 'mean_train_score': array([0.90900913, 0.32474186, 0.9966702 , 0.20667169, 1.        ,\n",
       "        0.11299991, 1.        , 0.11299991, 0.96333663, 0.60900166,\n",
       "        0.99966578, 0.23068431, 1.        , 0.11299991, 1.        ,\n",
       "        0.11299991, 0.99733687, 0.93835689, 1.        , 0.94799074,\n",
       "        1.        , 0.28711671, 1.        , 0.22266647, 1.        ,\n",
       "        0.99833421, 1.        , 0.99966578, 1.        , 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " 'std_train_score': array([3.42402435e-03, 2.81993116e-02, 1.32445386e-03, 1.88445785e-03,\n",
       "        0.00000000e+00, 3.20002276e-05, 0.00000000e+00, 3.20002276e-05,\n",
       "        1.23556434e-03, 6.24004437e-04, 3.34224599e-04, 6.61515815e-03,\n",
       "        0.00000000e+00, 3.20002276e-05, 0.00000000e+00, 3.20002276e-05,\n",
       "        1.32623165e-03, 8.83561839e-03, 0.00000000e+00, 3.47202469e-03,\n",
       "        0.00000000e+00, 4.37656446e-02, 0.00000000e+00, 7.28894072e-05,\n",
       "        0.00000000e+00, 3.28891228e-04, 0.00000000e+00, 3.34224599e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here plot score (accuracy) for each model. You can use \"plot_scores\" function.\n",
    "\n",
    "# Example: plot_scores(parameters, scores, \"title\", \"x_label\", \"y_label\"), \n",
    "\n",
    "# You can see an example in the follow.\n",
    "# Note that the visualizations/plots provided are just simple examples/illustrations. \n",
    "# We encourage more informative and alternate methods to present results.\n",
    "# plot_scores(x, y, title = \"Title\", x_label = \"X\", y_label = \"Y\"):\n",
    "svm_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here report the score for the best model\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the predictions\n",
    "# Example: vis_predictions(x_eval, y_pred, size_of_data)\n",
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "vis_predictions(x_test, y_predict, len(y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEQrdyLHsUIu"
   },
   "source": [
    "### 2.1.6: Summary\n",
    "\n",
    "Summarize your findings:\n",
    " * Which hyper-parameters were important and how did they influence your results?\n",
    " * What were other design choices you faced?\n",
    " * Any other interesting insights..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fcq52WUUs2Mm"
   },
   "source": [
    "# 2.2: Model [M2]: *fill-this-in* (25 points)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1: Hyper-parameters\n",
    "\n",
    "Define hyper-parameters for your method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2: Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28]) torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "# e.g. normalize, flatten input data.\n",
    "# convert data to torch.FloatTensor\n",
    "mean_train_data = training_data.train_data.float().mean()/255\n",
    "std_train_data = training_data.train_data.float().std()/255\n",
    "\n",
    "mean_test_data = test_data.test_data.float().mean()/255\n",
    "std_test_data = test_data.test_data.float().std()/255\n",
    "\n",
    "\n",
    "# train_transform = transforms.Compose([transform.ToTensor(),\n",
    "#                                torchvision.transforms.Normalize((mean_train_data, ), (std_train_data,))])\n",
    "\n",
    "# test_transform = transforms.Compose([transform.ToTensor(),\n",
    "#                                torchvision.transforms.Normalize((mean_test_data, ), (std_test_data,))]) \n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data/mnist', train=True,\n",
    "                                   download=True, transform=torchvision.transforms.Compose([\n",
    "                                  torchvision.transforms.ToTensor(),\n",
    "                                  torchvision.transforms.Normalize((mean_train_data, ), (std_train_data,))]))\n",
    "test_data = datasets.MNIST(root='data/mnist', train=False,\n",
    "                                  download=True, transform=torchvision.transforms.Compose([\n",
    "                                  torchvision.transforms.ToTensor(),\n",
    "                                  torchvision.transforms.Normalize((mean_test_data, ), (std_test_data,))]))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size_train)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test)\n",
    "\n",
    "print(train_data.train_data.shape, test_data.test_data.shape, train_data.targets.shape)\n",
    "\n",
    "# For gridsearch\n",
    "X_trf = train_data.data.reshape(-1, 1, 28, 28).float()\n",
    "X_trf = X_trf.numpy()\n",
    "\n",
    "# X_trf = X_trf.astype()\n",
    "y_trf = train_data.targets.long()\n",
    "y_trf = y_trf.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3: Model\n",
    "\n",
    "Define your model here (all hyper-parameters in 2.1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4: Fit Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (fc2): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_units=784, drop=0.2):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, num_units)\n",
    "        self.fc2 = nn.Linear(num_units, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        # with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "# initialisng the NN\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr=0.001, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.5818       -5.9603  4.6622\n",
      "      2       -6.1247       0.6609       -6.2911  4.0002\n",
      "      3       -6.3777       0.6935       -6.4879  3.9892\n",
      "      4       -6.5437       0.7112       -6.6285  3.9960\n",
      "      5       -6.6678       0.7242       -6.7381  3.9392\n",
      "      6       -6.7670       0.7331       -6.8279  3.9820\n",
      "      7       -6.8497       0.7420       -6.9040  3.9869\n",
      "[CV]  lr=0.001, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   31.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr=0.001, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.6258       -5.9290  3.8742\n",
      "      2       -6.1163       0.7019       -6.2702  4.0411\n",
      "      3       -6.3746       0.7345       -6.4707  3.9844\n",
      "      4       -6.5429       0.7493       -6.6133  4.1197\n",
      "      5       -6.6682       0.7587       -6.7240  3.9415\n",
      "      6       -6.7682       0.7646       -6.8146  3.9816\n",
      "      7       -6.8515       0.7687       -6.8913  3.9883\n",
      "[CV]  lr=0.001, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  29.8s\n",
      "[CV] lr=0.001, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.5218       -5.9473  3.9861\n",
      "      2       -6.1348       0.6487       -6.2796  4.0032\n",
      "      3       -6.3878       0.6977       -6.4769  3.9940\n",
      "      4       -6.5538       0.7208       -6.6179  3.9706\n",
      "      5       -6.6779       0.7365       -6.7276  4.0449\n",
      "      6       -6.7771       0.7474       -6.8176  4.0079\n",
      "      7       -6.8597       0.7525       -6.8937  4.0840\n",
      "[CV]  lr=0.001, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  29.8s\n",
      "[CV] lr=0.001, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.2761       -5.9813  2.9139\n",
      "      2       -6.1441       0.4310       -6.3035  2.9631\n",
      "      3       -6.3906       0.5429       -6.4966  2.9665\n",
      "      4       -6.5535       0.6121       -6.6353  2.9106\n",
      "      5       -6.6757       0.6548       -6.7436  2.8904\n",
      "      6       -6.7737       0.6839       -6.8325  2.9271\n",
      "      7       -6.8554       0.7042       -6.9079  2.9438\n",
      "[CV]  lr=0.001, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  22.0s\n",
      "[CV] lr=0.001, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.6346       -5.9299  2.9277\n",
      "      2       -6.1196       0.7049       -6.2698  2.9279\n",
      "      3       -6.3765       0.7340       -6.4700  2.9667\n",
      "      4       -6.5442       0.7483       -6.6125  2.9436\n",
      "      5       -6.6692       0.7579       -6.7232  2.9607\n",
      "      6       -6.7690       0.7664       -6.8138  2.9250\n",
      "      7       -6.8521       0.7699       -6.8905  2.9387\n",
      "[CV]  lr=0.001, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  22.1s\n",
      "[CV] lr=0.001, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.5009       -5.9618  2.9716\n",
      "      2       -6.1426       0.6332       -6.2888  2.9450\n",
      "      3       -6.3930       0.6916       -6.4839  2.9896\n",
      "      4       -6.5577       0.7224       -6.6236  2.9003\n",
      "      5       -6.6811       0.7404       -6.7325  2.9638\n",
      "      6       -6.7797       0.7514       -6.8218  2.9818\n",
      "      7       -6.8621       0.7599       -6.8975  3.0039\n",
      "[CV]  lr=0.001, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  22.2s\n",
      "[CV] lr=0.001, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.6541       -5.9451  3.9922\n",
      "      2       -6.1147       0.7184       -6.2828  3.9725\n",
      "      3       -6.3715       0.7410       -6.4821  3.9742\n",
      "      4       -6.5392       0.7507       -6.6241  4.0485\n",
      "      5       -6.6642       0.7592       -6.7345  3.9763\n",
      "      6       -6.7640       0.7648       -6.8248  3.9703\n",
      "      7       -6.8472       0.7691       -6.9013  4.0193\n",
      "[CV]  lr=0.001, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  29.8s\n",
      "[CV] lr=0.001, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.6261       -5.9509  3.9470\n",
      "      2       -6.1320       0.7006       -6.2817  4.0354\n",
      "      3       -6.3841       0.7376       -6.4786  4.0394\n",
      "      4       -6.5497       0.7556       -6.6193  4.0026\n",
      "      5       -6.6736       0.7670       -6.7289  3.9569\n",
      "      6       -6.7726       0.7719       -6.8188  4.0344\n",
      "      7       -6.8552       0.7777       -6.8949  3.9934\n",
      "[CV]  lr=0.001, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  29.6s\n",
      "[CV] lr=0.001, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.5886       -5.9355  4.1725\n",
      "      2       -6.1277       0.6721       -6.2726  4.1361\n",
      "      3       -6.3833       0.7073       -6.4718  4.2509\n",
      "      4       -6.5504       0.7277       -6.6138  4.1487\n",
      "      5       -6.6752       0.7382       -6.7243  4.2292\n",
      "      6       -6.7748       0.7472       -6.8146  4.2232\n",
      "      7       -6.8578       0.7524       -6.8911  3.9980\n",
      "[CV]  lr=0.001, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  31.0s\n",
      "[CV] lr=0.001, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.5697       -5.9482  2.9345\n",
      "      2       -6.1182       0.6790       -6.2844  2.9780\n",
      "      3       -6.3738       0.7227       -6.4831  2.9441\n",
      "      4       -6.5409       0.7430       -6.6248  2.9503\n",
      "      5       -6.6656       0.7530       -6.7350  2.9471\n",
      "      6       -6.7652       0.7605       -6.8252  2.9349\n",
      "      7       -6.8482       0.7633       -6.9016  2.9744\n",
      "[CV]  lr=0.001, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  22.2s\n",
      "[CV] lr=0.001, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.5065       -5.9768  2.9903\n",
      "      2       -6.1468       0.6213       -6.2972  3.0342\n",
      "      3       -6.3935       0.6700       -6.4899  2.9178\n",
      "      4       -6.5567       0.6993       -6.6283  2.9220\n",
      "      5       -6.6791       0.7174       -6.7365  2.9652\n",
      "      6       -6.7773       0.7290       -6.8253  2.9551\n",
      "      7       -6.8592       0.7370       -6.9007  2.9970\n",
      "[CV]  lr=0.001, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  22.4s\n",
      "[CV] lr=0.001, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.1159       -6.1084  2.8980\n",
      "      2       -6.2693       0.1779       -6.3948  2.9576\n",
      "      3       -6.4908       0.2600       -6.5696  2.9573\n",
      "      4       -6.6392       0.3342       -6.6963  2.9371\n",
      "      5       -6.7515       0.3873       -6.7961  2.9554\n",
      "      6       -6.8421       0.4315       -6.8785  2.9233\n",
      "      7       -6.9181       0.4701       -6.9488  3.0153\n",
      "[CV]  lr=0.001, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  22.2s\n",
      "[CV] lr=0.01, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7236       -7.0929  3.9878\n",
      "      2       -7.2638       0.7517       -7.4313  3.9935\n",
      "      3       -7.5210       0.7603       -7.6311  4.0039\n",
      "      4       -7.6890       0.7672       -7.7734  3.9934\n",
      "      5       -7.8142       0.7717       -7.8841  4.0620\n",
      "      6       -7.9142       0.7723       -7.9746  4.3431\n",
      "      7       -7.9974       0.7733       -8.0512  4.2282\n",
      "[CV]  lr=0.01, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  30.6s\n",
      "[CV] lr=0.01, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7418       -7.0847  4.0733\n",
      "      2       -7.2693       0.7679       -7.4228  4.1727\n",
      "      3       -7.5262       0.7769       -7.6225  4.3861\n",
      "      4       -7.6941       0.7802       -7.7648  4.0962\n",
      "      5       -7.8193       0.7821       -7.8755  4.0594\n",
      "      6       -7.9192       0.7837       -7.9660  4.1584\n",
      "      7       -8.0024       0.7857       -8.0426  4.0085\n",
      "[CV]  lr=0.01, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  30.8s\n",
      "[CV] lr=0.01, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.6946       -7.0952  3.9645\n",
      "      2       -7.2835       0.7549       -7.4278  4.1630\n",
      "      3       -7.5368       0.7725       -7.6256  4.1473\n",
      "      4       -7.7031       0.7814       -7.7669  4.5070\n",
      "      5       -7.8274       0.7854       -7.8769  4.3713\n",
      "      6       -7.9268       0.7874       -7.9670  4.0012\n",
      "      7       -8.0096       0.7891       -8.0434  3.9938\n",
      "[CV]  lr=0.01, module__drop=0.2, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  31.1s\n",
      "[CV] lr=0.01, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.6658       -7.1041  2.9581\n",
      "      2       -7.2716       0.7448       -7.4377  2.8776\n",
      "      3       -7.5260       0.7650       -7.6356  2.9516\n",
      "      4       -7.6926       0.7742       -7.7769  2.9990\n",
      "      5       -7.8171       0.7765       -7.8869  3.0989\n",
      "      6       -7.9166       0.7793       -7.9770  3.3400\n",
      "      7       -7.9995       0.7805       -8.0533  3.2480\n",
      "[CV]  lr=0.01, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  23.3s\n",
      "[CV] lr=0.01, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.5921       -7.1192  2.9414\n",
      "      2       -7.2979       0.7058       -7.4436  3.0499\n",
      "      3       -7.5454       0.7423       -7.6375  3.0677\n",
      "      4       -7.7086       0.7551       -7.7765  2.9718\n",
      "      5       -7.8310       0.7622       -7.8850  3.0275\n",
      "      6       -7.9291       0.7687       -7.9740  3.0187\n",
      "      7       -8.0109       0.7716       -8.0495  3.0229\n",
      "[CV]  lr=0.01, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  22.7s\n",
      "[CV] lr=0.01, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.1323       -7.2117  2.9699\n",
      "      2       -7.3837       0.1726       -7.5181  2.9741\n",
      "      3       -7.6176       0.2021       -7.7009  2.9341\n",
      "      4       -7.7718       0.2270       -7.8321  3.1127\n",
      "      5       -7.8876       0.2515       -7.9347  2.9587\n",
      "      6       -7.9805       0.2804       -8.0190  3.3996\n",
      "      7       -8.0582       0.3073       -8.0908  3.4658\n",
      "[CV]  lr=0.01, module__drop=0.2, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  23.8s\n",
      "[CV] lr=0.01, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7528       -7.0894  4.5430\n",
      "      2       -7.2620       0.7682       -7.4292  4.6329\n",
      "      3       -7.5199       0.7730       -7.6295  4.1202\n",
      "      4       -7.6881       0.7741       -7.7722  4.0458\n",
      "      5       -7.8135       0.7760       -7.8830  3.9888\n",
      "      6       -7.9136       0.7778       -7.9736  4.0212\n",
      "      7       -7.9969       0.7793       -8.0504  3.9861\n",
      "[CV]  lr=0.01, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  31.2s\n",
      "[CV] lr=0.01, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7800       -7.0816  4.0082\n",
      "      2       -7.2668       0.7886       -7.4212  4.0410\n",
      "      3       -7.5247       0.7890       -7.6215  3.9722\n",
      "      4       -7.6930       0.7899       -7.7641  4.0283\n",
      "      5       -7.8184       0.7924       -7.8748  4.0424\n",
      "      6       -7.9185       0.7929       -7.9655  4.5122\n",
      "      7       -8.0018       0.7929       -8.0422  4.3037\n",
      "[CV]  lr=0.01, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  30.9s\n",
      "[CV] lr=0.01, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.6357       -7.1068  4.3736\n",
      "      2       -7.2916       0.7107       -7.4354  4.4062\n",
      "      3       -7.5425       0.7395       -7.6312  4.1292\n",
      "      4       -7.7075       0.7529       -7.7714  3.9954\n",
      "      5       -7.8309       0.7616       -7.8807  4.0836\n",
      "      6       -7.9298       0.7690       -7.9703  4.0267\n",
      "      7       -8.0122       0.7730       -8.0463  4.0191\n",
      "[CV]  lr=0.01, module__drop=0.4, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  30.7s\n",
      "[CV] lr=0.01, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7552       -7.0878  3.0799\n",
      "      2       -7.2604       0.7720       -7.4285  3.0166\n",
      "      3       -7.5189       0.7793       -7.6291  2.9910\n",
      "      4       -7.6874       0.7820       -7.7719  3.2814\n",
      "      5       -7.8130       0.7841       -7.8828  3.1301\n",
      "      6       -7.9132       0.7850       -7.9735  3.1337\n",
      "      7       -7.9966       0.7857       -8.0502  3.2513\n",
      "[CV]  lr=0.01, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  23.7s\n",
      "[CV] lr=0.01, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7205       -7.0941  3.1858\n",
      "      2       -7.2770       0.7667       -7.4279  3.3789\n",
      "      3       -7.5310       0.7776       -7.6260  3.2832\n",
      "      4       -7.6976       0.7809       -7.7674  3.8148\n",
      "      5       -7.8220       0.7830       -7.8775  3.5920\n",
      "      6       -7.9215       0.7846       -7.9677  3.2048\n",
      "      7       -8.0044       0.7849       -8.0441  3.0241\n",
      "[CV]  lr=0.01, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  25.4s\n",
      "[CV] lr=0.01, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.3484       -7.1284  3.0920\n",
      "      2       -7.3085       0.5352       -7.4490  3.2068\n",
      "      3       -7.5539       0.6159       -7.6413  3.5211\n",
      "      4       -7.7162       0.6660       -7.7794  3.3138\n",
      "      5       -7.8381       0.6971       -7.8874  3.5442\n",
      "      6       -7.9358       0.7192       -7.9760  3.2249\n",
      "      7       -8.0174       0.7342       -8.0513  2.9310\n",
      "[CV]  lr=0.01, module__drop=0.4, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=  24.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 11.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "Re-initializing module because the following parameters were re-set: drop, num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7613       -7.2843  6.4269\n",
      "      2       -7.4606       0.7763       -7.6288  6.6182\n",
      "      3       -7.7213       0.7824       -7.8307  6.1845\n",
      "      4       -7.8907       0.7853       -7.9741  6.1555\n",
      "      5       -8.0168       0.7873       -8.0854  6.4873\n",
      "      6       -8.1173       0.7878       -8.1764  6.2396\n",
      "      7       -8.2009       0.7887       -8.2533  6.2904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=Net(\n",
       "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (fc2): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  ),\n",
       "),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'lr': [0.001, 0.01], 'optimizer': [<class 'torch.optim.sgd.SGD'>], 'module__num_units': [784, 512], 'module__drop': [0.2, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net = NeuralNetClassifier(\n",
    "    model,\n",
    "    max_epochs=7,\n",
    "    lr=0.1,\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer_momentum=0.9,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_valid_shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "params = {\n",
    "    'lr': [0.001, 0.01],\n",
    "    'optimizer': [optim.SGD], #tried Adam also\n",
    "    'module__num_units': [784, 512],\n",
    "    'module__drop': [0.2, 0.4]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = sklearn.model_selection.GridSearchCV(net, params, refit=True, scoring='accuracy', verbose=2, cv=3)\n",
    "grid_search.fit(X_trf, y_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Net(\n",
       "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (fc2): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.069463\n",
      "Epoch: 2 \tTraining Loss: 1.344382\n",
      "Epoch: 3 \tTraining Loss: 1.237780\n",
      "Epoch: 4 \tTraining Loss: 0.860631\n",
      "Epoch: 5 \tTraining Loss: 0.460861\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss\n",
    "        ))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr=0.001, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.1331           inf  3.1314\n",
      "      2           inf       0.1711       -6.0950  3.0039\n",
      "      3       -6.2368       0.2136       -6.3147  2.9147\n",
      "[CV]  lr=0.001, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr=0.001, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.4983       -5.8427  3.0302\n",
      "      2       -6.0161       0.6510       -6.1618  3.0521\n",
      "      3       -6.2614       0.7036       -6.3542  2.9703\n",
      "[CV]  lr=0.001, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  10.5s\n",
      "[CV] lr=0.001, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.1044       -6.1022  2.2012\n",
      "      2       -6.2789       0.1044       -6.3758  2.2384\n",
      "      3       -6.4886       0.1044       -6.5410  2.2364\n",
      "[CV]  lr=0.001, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=   7.9s\n",
      "[CV] lr=0.001, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.4692       -5.8619  2.2445\n",
      "      2       -6.0302       0.5924       -6.1738  2.2685\n",
      "      3       -6.2709       0.6425       -6.3629  2.1826\n",
      "[CV]  lr=0.001, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=   8.0s\n",
      "[CV] lr=0.01, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.6438       -6.9294  2.9612\n",
      "      2       -7.1367       0.7008       -7.2603  3.0101\n",
      "      3       -7.3893       0.7235       -7.4574  3.0202\n",
      "[CV]  lr=0.01, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  10.4s\n",
      "[CV] lr=0.01, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7606       -6.9480  2.9830\n",
      "      2       -7.1335       0.7764       -7.2869  3.0396\n",
      "      3       -7.3910       0.7829       -7.4870  3.1671\n",
      "[CV]  lr=0.01, module__num_units=784, optimizer=<class 'torch.optim.sgd.SGD'>, total=  10.8s\n",
      "[CV] lr=0.01, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.7391       -6.9161  2.3174\n",
      "      2       -7.1265       0.7573       -7.2531  2.2107\n",
      "      3       -7.3829       0.7638       -7.4524  2.2404\n",
      "[CV]  lr=0.01, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=   7.9s\n",
      "[CV] lr=0.01, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           inf       0.0911       -7.0572  2.2349\n",
      "      2       -7.2180       0.1076       -7.3636  2.2212\n",
      "      3       -7.4536       0.1465       -7.5478  2.1722\n",
      "[CV]  lr=0.01, module__num_units=512, optimizer=<class 'torch.optim.sgd.SGD'>, total=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=Net(\n",
       "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (fc2): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  ),\n",
       "),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'lr': [0.001, 0.01], 'optimizer': [<class 'torch.optim.sgd.SGD'>], 'module__num_units': [784, 512]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "params = {\n",
    "    'lr': [0.001, 0.01],\n",
    "    'optimizer': [optim.SGD],\n",
    "    'module__num_units': [784, 512],\n",
    "    'module__drop': [0.2, 0.4]\n",
    "}\n",
    "\n",
    "gs = sklearn.model_selection.GridSearchCV(net, params, refit=False, scoring='accuracy', verbose=2, cv=2)\n",
    "\n",
    "gs.fit(X_trf, y_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.01, 'module__num_units': 784, 'optimizer': torch.optim.sgd.SGD}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: -0.0939, Accuracy: 4/10000 (0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0 \n",
    "    correct = 0 \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset), \n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5: Evaluation\n",
    "\n",
    "Evaluate your model.\n",
    "  * Evaluate models with different parameters \n",
    "  * Plot score (accuracy) for each model using \"plot_scores\" function\n",
    "  * Report the score for the best model\n",
    "  * Use \"vis_predictions\" function to visualize few examples of test/validation set with the corresponding predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here plot score (accuracy) for each model. You can use \"plot_scores\" function.\n",
    "\n",
    "# Example: plot_scores(parameters, scores, \"title\", \"x_label\", \"y_label\"), \n",
    "\n",
    "# You can see an example in the follow.\n",
    "# Note that the visualizations/plots provided are just simple examples/illustrations. \n",
    "# We encourage more informative and alternate methods to present results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here report the score for the best model\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the predictions\n",
    "# Example: vis_predictions(x_eval, y_pred, size_of_data)\n",
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6: Summary\n",
    "\n",
    "Summarize your findings:\n",
    " * Which hyper-parameters were important and how did they influence your results?\n",
    " * What were other design choices you faced?\n",
    " * Any other interesting insights..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3: Model [M3] (Neural Networks): *fill-this-in* (25 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1: Hyper-parameters\n",
    "\n",
    "Define hyper-parameters for your method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size_train = 64 # Fill in\n",
    "batch_size_test = 1000 # Fill in\n",
    "n_epochs = 10 # Fill in\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "\n",
    "test_set = 'val'  #  or 'test'\n",
    "# Decide all your hyperparameters based on validation performance\n",
    "# Then, switch to 'test' for final evaluation\n",
    "\n",
    "if test_set == 'val':\n",
    "    train_idxs, val_idxs = ..., ...   # Fill in\n",
    "    x_train, y_train = x_trainval[train_idxs], y_trainval[train_idxs]\n",
    "    x_eval, y_eval = x_trainval[val_idxs], y_trainval[val_idxs]\n",
    "else:\n",
    "    x_train, y_train = x_trainval, y_trainval\n",
    "    x_eval, y_eval = x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2: Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_train_data = training_data.train_data.float().mean()/255\n",
    "std_train_data = training_data.train_data.float().std()/255\n",
    "\n",
    "mean_test_data = test_data.test_data.float().mean()/255\n",
    "std_test_data = test_data.test_data.float().std()/255\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('data/mnist/', train=True, download=False,\n",
    "                              transform=torchvision.transforms.Compose([\n",
    "                                  torchvision.transforms.ToTensor(),\n",
    "                                  torchvision.transforms.Normalize((mean_train_data, ), (std_train_data,))\n",
    "                              ])), batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('data/mnist/', train=False, download=False,\n",
    "                              transform=torchvision.transforms.Compose([\n",
    "                                  torchvision.transforms.ToTensor(),\n",
    "                              ])), batch_size=batch_size_test, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3: Model\n",
    "\n",
    "Define your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 10 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "[-0.9658346  -2.1890705   0.16985609  0.8138456  -3.375209   -2.1430597\n",
      " -0.39585084  2.9419577  -2.1910605   1.2443967   0.04351204 -0.5150961\n",
      " -0.86073655 -1.1097169   0.31839254 -0.8231973  -1.056304   -0.89645284\n",
      "  0.3759244  -1.0849651 ] (1000,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 28, 28)\n",
      "(3000, 1, 28, 28)\n",
      "[[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.  51. 159. 253. 159.  50.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    48. 238. 252. 252. 252. 237.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n",
      "   227. 253. 252. 239. 233. 252.  57.   6.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  60. 224.\n",
      "   252. 253. 252. 202.  84. 252. 253. 122.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 252. 252.\n",
      "   252. 253. 252. 252.  96. 189. 253. 167.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 238. 253. 253.\n",
      "   190. 114. 253. 228.  47.  79. 255. 168.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 238. 252. 252. 179.\n",
      "    12.  75. 121.  21.   0.   0. 253. 243.  50.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.  38. 165. 253. 233. 208.  84.\n",
      "     0.   0.   0.   0.   0.   0. 253. 252. 165.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   7. 178. 252. 240.  71.  19.  28.\n",
      "     0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.  57. 252. 252.  63.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0. 198. 253. 190.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0. 255. 253. 196.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  76. 246. 252. 112.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0. 253. 252. 148.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  85. 252. 230.  25.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   7. 135. 253. 186.  12.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  85. 252. 223.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   7. 131. 252. 225.  71.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  85. 252. 145.   0.   0.   0.   0.   0.\n",
      "     0.   0.  48. 165. 252. 173.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  86. 253. 225.   0.   0.   0.   0.   0.\n",
      "     0. 114. 238. 253. 162.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  85. 252. 249. 146.  48.  29.  85. 178.\n",
      "   225. 253. 223. 167.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  85. 252. 252. 252. 229. 215. 252. 252.\n",
      "   252. 196. 130.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.  28. 199. 252. 252. 253. 252. 252. 233.\n",
      "   145.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.  25. 128. 252. 253. 252. 141.  37.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_trainval_3d.shape)\n",
    "x_rr = x_trainval_3d.reshape(-1, 1, 28, 28).astype(np.double)\n",
    "print(x_rr.shape)\n",
    "x_tensor = torchvision.datasets.MNIST(dataset_dir,train=True, transform=torchvision.transforms.Compose([\n",
    "    \n",
    "torchvision.transforms.ToTensor()]), \n",
    "                                     target_transform=None, download=True)\n",
    "\n",
    "print(x_rr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs):\n",
    "    net.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset), \n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            \n",
    "            torch.save(net.state_dict(), 'results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    test_loss = 0 \n",
    "    correct = 0 \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset), \n",
    "            100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4: Fit Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.410626\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.129496\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.304248\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.890438\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.742229\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.457234\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.627806\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.518887\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.496197\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.332545\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.310364\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.352632\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.307824\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.626980\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.290504\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.172360\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.376751\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.323089\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.408547\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.230783\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.262067\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.245256\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.227878\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.156444\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.245723\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.247120\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.200127\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.119246\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.571699\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.105960\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.290599\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.249784\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.427000\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.307111\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.357016\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.122566\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.260679\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.344586\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.253148\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.186942\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.480782\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.295486\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.325359\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.266697\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.297544\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.327108\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.190808\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.226934\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.071187\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.084435\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.155438\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.153809\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.198837\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.425108\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.265213\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.146221\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.287121\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.254693\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.214876\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.200423\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.139222\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.198685\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.280913\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.190976\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.086013\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.177322\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.158509\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.408835\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.330730\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.057923\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.277352\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.336209\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.248309\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.181054\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.134770\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.143283\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.197047\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.224766\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.196665\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.195749\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.187194\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.154996\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.161775\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.137152\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.197776\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.125319\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.107405\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.243275\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.256970\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.150754\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.201355\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.140919\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.164781\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.107273\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.314660\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.261720\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.151329\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.196286\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.152945\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.171174\n",
      "\n",
      "Test set: Avg. loss: 0.3065, Accuracy: 9817/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr= learning_rate, momentum=momentum)\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "  train(epoch)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model using torch.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5: Evaluation\n",
    "\n",
    "Evaluate your model.\n",
    "\n",
    "  * Loss curves: Plot epoch (# passes over training data) and loss\n",
    "  * Accuracy curves: Plot epoch and accuracy over val/test set\n",
    "  * Final numbers: Report final accuracy numbers for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "C:\\ProgramData\\Miniconda3\\envs\\DSP\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3122, Accuracy: 1013/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.348203\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.294684\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.283304\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.255229\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.268497\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.290261\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.220231\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.173445\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.163646\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.107237\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.900147\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.887998\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.770982\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.652572\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.604293\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.760816\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.530188\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.529381\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.243213\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.069740\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.047342\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.961768\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.892022\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.857553\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.096149\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.038927\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.806223\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.749582\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.795092\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.865336\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.728324\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.911148\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.757045\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.923249\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.502978\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.744856\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.825184\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 1.179631\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.482757\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.717879\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.736722\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.486513\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.564251\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.738786\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.638890\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.540875\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.675251\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.538795\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.598562\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.528378\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.628966\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.753958\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.449205\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.734715\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.412914\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.566511\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.549390\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.598806\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.458691\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.691360\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.508299\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.466251\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.441889\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.506897\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.399575\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.503892\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.495165\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.373685\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.363609\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.487745\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.409609\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.500693\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.490688\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.550967\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.541074\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.666267\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.386406\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.379295\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.474701\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.474159\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.414444\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.539769\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.291061\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.254645\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.444010\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.571739\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.365657\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.404777\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.537769\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.242876\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.358172\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.389979\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.572771\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.418974\n",
      "\n",
      "Test set: Avg. loss: 0.6283, Accuracy: 9466/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.281861\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.320151\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.228423\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.385924\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.655363\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.384307\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.461620\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.466741\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.364848\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.255324\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.395770\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.445314\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.425939\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.358256\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.563977\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.415231\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.490758\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.445456\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.412422\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.256516\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.345377\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.175087\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.434163\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.263869\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.343057\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.283162\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.311206\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.333735\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.430272\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.339522\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.423392\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.371894\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.560138\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.478601\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.353797\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.293103\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.343269\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.422433\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.388829\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.252681\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.573811\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.317182\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.576966\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.296376\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.277544\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.259708\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.350023\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.309481\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.298519\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.534617\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.250464\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.348519\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.467543\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.264092\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.368380\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.325734\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.248427\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.230471\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.709635\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.191693\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.255336\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.305862\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.316186\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.400898\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.214165\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.278643\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.732239\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.416180\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.635622\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.112536\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.309221\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.501653\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.551769\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.279980\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.229576\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.614606\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.295392\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.323297\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.344058\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.202925\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.471936\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.198064\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.339359\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.441438\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.410918\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.171978\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.355327\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.248065\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.221736\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.292421\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.304425\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.248274\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.289841\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.493440\n",
      "\n",
      "Test set: Avg. loss: 0.4677, Accuracy: 9663/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.209051\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.373370\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.261481\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.211369\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.543089\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.421951\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.250852\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.309959\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.332806\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.562704\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.284848\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.155655\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.236367\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.656357\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.214379\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.282461\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.324935\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.179605\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.268320\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.389859\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.194086\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.271745\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.260580\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.225023\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.394203\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.486154\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.433745\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.295870\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.308918\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.331928\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.639808\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.316626\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.308785\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.288649\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.376926\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.362099\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.230726\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.246369\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.401089\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.142042\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.504477\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.270815\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.350193\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.274757\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.264495\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.372772\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.178419\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.110096\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.196583\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.386334\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.333955\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.255659\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.244050\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.635012\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.301614\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.177023\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.176102\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.326134\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.262567\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.374235\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.186007\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.264903\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.326886\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.164594\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.308018\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.247726\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.359179\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.308780\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.205956\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.263802\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.333128\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.366613\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.300214\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.145904\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.231868\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.240511\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.280071\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.207137\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.134872\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.161995\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.296362\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.265416\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.483834\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.287048\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.289113\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.171915\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.307105\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.174604\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.248658\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.353464\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.139127\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.461881\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.384900\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.243379\n",
      "\n",
      "Test set: Avg. loss: 0.4043, Accuracy: 9718/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here plot epoch (# passes over training data) and loss\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here plot epoch and accuracy over val/test set\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "# Example:\n",
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(\"PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here report the score for the best model\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the predictions\n",
    "# Example: vis_predictions(x_eval, y_pred, size_of_data)\n",
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6: Summary\n",
    "\n",
    "Summarize your findings:\n",
    " * Which hyper-parameters were important and how did they influence your results?\n",
    " * What were other design choices you faced?\n",
    " * Any other interesting insights..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ex3qQp3JolD1"
   },
   "source": [
    "# 3. Summary (20 points)\n",
    "\n",
    "Enter your final summary here.\n",
    "\n",
    "You should now compare performance  on the three models [M1], [M2] and [M3]. Present this in a tabular format and/or using plots.\n",
    "\n",
    "Which model do you recommend to perform digit classification and why?\n",
    "\n",
    "Feel free to discuss other insightful observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pa6rPT53LUW8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLCySec Project 1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
